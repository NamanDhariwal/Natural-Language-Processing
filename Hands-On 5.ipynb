{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e300b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk             # Actually not useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf44691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK:\n",
    "\n",
    "# Converting a text dpcumne tin a numeric vector and comparing two numeric vector of text data!\n",
    "# We use, COSINE DISTANCE between the two vectors. the higher the angle => more originality!\n",
    "# Vectorization: \n",
    "#     1. fit ()\n",
    "#     2. transform() - gives a 1D array as output\n",
    "\n",
    "# Create a corpus of Lakshmi Shankaran's articles.\n",
    "# Then take two other articles of her and find the cosine distance between the two articles and check originality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215f4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a635bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I have a German Shepherd\", \"German Shepherd is from Germany\", \"Germans love gossiping\"]   # 3 Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69fe73a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(binary=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(binary=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac7043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0b0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from:0\n",
      "german:1\n",
      "germans:2\n",
      "germany:3\n",
      "gossiping:4\n",
      "have:5\n",
      "is:6\n",
      "love:7\n",
      "shepherd:8\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key, vocab[key]))     # Unique words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a94d254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform([\"Germany has German Shepherd\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f91f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([\"Germany has German Shepherd\"]).toarray(), vect.transform([\"Germany has Berlin as capital\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e99a8b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de09cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus of Lakshmi Shankaran's articles' first paragraph \n",
    "# Then choose a newer article's first para and find cosine distance between them to find % of originality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "406e71a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:0\n",
      "12:1\n",
      "13:2\n",
      "about:3\n",
      "adequate:4\n",
      "after:5\n",
      "against:6\n",
      "ahead:7\n",
      "am:8\n",
      "an:9\n",
      "and:10\n",
      "approximation:11\n",
      "arch:12\n",
      "are:13\n",
      "arms:14\n",
      "as:15\n",
      "at:16\n",
      "beach:17\n",
      "belmond:18\n",
      "bios:19\n",
      "blindingly:20\n",
      "blocking:21\n",
      "boat:22\n",
      "bottle:23\n",
      "bouncers:24\n",
      "bridge:25\n",
      "bright:26\n",
      "burly:27\n",
      "but:28\n",
      "captain:29\n",
      "casually:30\n",
      "chatter:31\n",
      "circle:32\n",
      "clarify:33\n",
      "clear:34\n",
      "contrary:35\n",
      "corals:36\n",
      "couple:37\n",
      "day:38\n",
      "death:39\n",
      "depth:40\n",
      "desire:41\n",
      "devotees:42\n",
      "doesn:43\n",
      "editing:44\n",
      "eels:45\n",
      "elton:46\n",
      "emotion:47\n",
      "enslaved:48\n",
      "entrance:49\n",
      "entry:50\n",
      "feel:51\n",
      "few:52\n",
      "field:53\n",
      "five:54\n",
      "flaunt:55\n",
      "for:56\n",
      "foreign:57\n",
      "from:58\n",
      "fruit:59\n",
      "gasping:60\n",
      "giant:61\n",
      "grisly:62\n",
      "guard:63\n",
      "had:64\n",
      "half:65\n",
      "hands:66\n",
      "has:67\n",
      "have:68\n",
      "heat:69\n",
      "heaven:70\n",
      "home:71\n",
      "horns:72\n",
      "ideal:73\n",
      "if:74\n",
      "ilk:75\n",
      "in:76\n",
      "infernal:77\n",
      "instructors:78\n",
      "into:79\n",
      "is:80\n",
      "it:81\n",
      "john:82\n",
      "juices:83\n",
      "just:84\n",
      "khun:85\n",
      "kilometres:86\n",
      "koh:87\n",
      "last:88\n",
      "leading:89\n",
      "leaning:90\n",
      "lie:91\n",
      "life:92\n",
      "like:93\n",
      "love:94\n",
      "lunch:95\n",
      "lush:96\n",
      "macarons:97\n",
      "made:98\n",
      "magazine:99\n",
      "massive:100\n",
      "me:101\n",
      "moat:102\n",
      "mortal:103\n",
      "my:104\n",
      "napasai:105\n",
      "nearby:106\n",
      "nirvana:107\n",
      "not:108\n",
      "now:109\n",
      "oddly:110\n",
      "of:111\n",
      "on:112\n",
      "online:113\n",
      "or:114\n",
      "others:115\n",
      "our:116\n",
      "out:117\n",
      "outstretched:118\n",
      "over:119\n",
      "overhead:120\n",
      "overhear:121\n",
      "passion:122\n",
      "personal:123\n",
      "pg:124\n",
      "phangan:125\n",
      "phrase:126\n",
      "picnic:127\n",
      "poised:128\n",
      "poo:129\n",
      "prefer:130\n",
      "private:131\n",
      "professional:132\n",
      "protective:133\n",
      "proudly:134\n",
      "pumpui:135\n",
      "rahu:136\n",
      "rebirth:137\n",
      "resort:138\n",
      "restrict:139\n",
      "retire:140\n",
      "road:141\n",
      "rong:142\n",
      "samui:143\n",
      "sandwiches:144\n",
      "sentiment:145\n",
      "session:146\n",
      "shepherding:147\n",
      "skeletons:148\n",
      "snorkelling:149\n",
      "so:150\n",
      "some:151\n",
      "sparks:152\n",
      "spectre:153\n",
      "speedboat:154\n",
      "squint:155\n",
      "statues:156\n",
      "steps:157\n",
      "stucco:158\n",
      "stymied:159\n",
      "submission:160\n",
      "suggested:161\n",
      "sun:162\n",
      "swampland:163\n",
      "talking:164\n",
      "that:165\n",
      "the:166\n",
      "their:167\n",
      "there:168\n",
      "this:169\n",
      "those:170\n",
      "tiring:171\n",
      "to:172\n",
      "travel:173\n",
      "travellers:174\n",
      "tropical:175\n",
      "true:176\n",
      "two:177\n",
      "underwater:178\n",
      "wait:179\n",
      "walkway:180\n",
      "was:181\n",
      "wat:182\n",
      "waters:183\n",
      "we:184\n",
      "weather:185\n",
      "while:186\n",
      "who:187\n",
      "would:188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(binary = True)\n",
    "\n",
    "corpus_LS = [\"If there is a phrase I would prefer to retire from online bios, personal or professional, it is, I love travel. Or some approximation of that sentiment. To clarify, I am not against travellers or those who proudly flaunt their passion for travel. On the contrary, editing a travel magazine has now made me oddly protective of travellers and their ilk. My submission is that “love to travel,” suggested so casually, just doesn’t feel adequate to the depth of emotion it sparks in true devotees.\", \"Leaning out from a bridge leading into Wat Rong Khun, I squint at a stucco moat of outstretched hands and grisly skeletons. Two massive horns arch over the walkway, while a few steps ahead, giant statues of Death and Rahu guard the entrance, like burly bouncers poised to restrict my entry into heaven. “The bridge of rebirth,” I overhear a foreign couple talking. A swampland of desire—enslaved arms—lie in wait blocking a mortal’s road to nirvana. This was rebirth as an infernal spectre, not Elton John’s PG-13 Circle of Life.\", \"After a tiring snorkelling session in the clear waters of Koh Phangan, instructors Captain Pumpui and Captain Poo are shepherding me and five others on a private speedboat to nearby Bottle Beach for a picnic lunch of sandwiches, macarons and fruit juices. I am about 10-12 kilometres from Belmond Napasai’s lush tropical resort in Koh Samui, my home for the last day-and-a-half, and the sun is blindingly bright overhead. This is ideal snorkelling weather; we have had a field day gasping at eels and corals underwater. But the heat has stymied chatter on our boat.\"]\n",
    "vect.fit(corpus_LS)\n",
    "\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key, vocab[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f3eed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_LS = cosine_similarity(vect.transform([\"The world’s greatest cities are brutal, unsentimental places, precisely the reason why so many of us fall so irrevocably under their spell. In its worst hour, this bond can curdle into bitter complaints of unrequited affection and everyday torment. The subway doesn’t work, trash is overflowing and it’s too crowded; this is over. Let me assure you that right now someone somewhere is uttering these words about your dream metropolis, New York, Rome, Rio De Janeiro. Like an unrepentant cad, the city laughs in their face, Go on… live without me. Wresting long-term connections comes with the occasional pang of nostalgic regret. Those who can’t escape their love of cities are destined to keep replaying that first flush of romance, that moment when a city went from a destination to home.\"]).toarray(), vect.transform(corpus_LS).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cfa1fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38469699 0.178859   0.1987271 ]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_LS)     #  Will output 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "020832dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing a article's first paragrapgh with a couprs with 3 elements in it, which are also first paragraphs of articles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
